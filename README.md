# ğŸ§  Curriculum Learning em Ambientes de Reinforcement Learning

## ğŸ“Œ Objetivo do Projeto

Este projeto tem como objetivo investigar os efeitos da introduÃ§Ã£o de **Curriculum Learning (CL)** no processo de aprendizado por reforÃ§o. A proposta central Ã© comparar o desempenho de agentes treinados com e sem o uso de um currÃ­culo progressivo de tarefas, avaliando o impacto sobre mÃ©tricas relevantes como:

- â±ï¸ **Tempo de convergÃªncia**
- ğŸ¯ **Valor da recompensa na convergÃªncia**
- ğŸ² **Entropia da polÃ­tica durante o treinamento**

## ğŸ“ O que Ã© Curriculum Learning?

Curriculum Learning Ã© uma estratÃ©gia de treinamento inspirada na forma como humanos aprendem: comeÃ§ando por tarefas simples e progredindo para tarefas mais complexas. No contexto de RL, isso pode significar comeÃ§ar com versÃµes mais fÃ¡ceis de um ambiente e gradualmente aumentar sua complexidade Ã  medida que o agente melhora.

## ğŸ”¬ Metodologia

1. **SeleÃ§Ã£o de Ambientes**  
   Vamos selecionar alguns ambientes clÃ¡ssicos, como:
    - LunarLander-v2
    - MiniGridWorld
    ...

2. **DefiniÃ§Ã£o dos CurrÃ­culos**  
   Para cada ambiente, vamos estudar quais aspectos vamos quebrar em partes menores (a avaliaÃ§Ã£o faz parte do projeto).

3. **Arquitetura do Agente**  
   Os agentes utilizam algoritmos clÃ¡ssicos de RL como:
   - DQN
   - PPO
   - A2C  
   (Dependendo da configuraÃ§Ã£o experimental, via de regra, o PPO Ã© o mais utilizado.)

4. **Experimentos Comparativos**  
   Para cada ambiente:
   - Treinamento com currÃ­culo progressivo
   - Treinamento direto (sem currÃ­culo)
   - AnÃ¡lise quantitativa das mÃ©tricas definidas

## ğŸ“ˆ MÃ©tricas Avaliadas

- **Tempo de convergÃªncia**: NÃºmero de episÃ³dios atÃ© estabilizaÃ§Ã£o da recompensa mÃ©dia.
- **Recompensa final**: Valor mÃ©dio da recompensa nas Ãºltimas N iteraÃ§Ãµes.
- **Entropia da polÃ­tica**: AvaliaÃ§Ã£o da aleatoriedade das decisÃµes ao longo do tempo (quanto menor, mais determinÃ­stica a polÃ­tica).

## ğŸ§ª Resultados Esperados

A hipÃ³tese Ã© que o uso de curriculum learning:
- ReduzirÃ¡ o tempo de convergÃªncia,
- PermitirÃ¡ alcanÃ§ar recompensas mais altas (melhor polÃ­tica final),
- PromoverÃ¡ polÃ­ticas menos aleatÃ³rias, com entropia decrescente de forma mais estÃ¡vel.

## âš™ï¸ Requisitos

- Gymnasium ou Gym
- NumPy, Matplotlib, pandas
- Stable-Baselines3 (ou outra biblioteca de RL)
- Tensorboard


[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/bFrIHgJ3)
